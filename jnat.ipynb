{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text file\n",
    "\n",
    "Removing all unnecesary lines and characters from input file (<code>FSG.txt</code>).\n",
    "\n",
    "The end result is a text file with only lines containing words and no dashes at the end of the line.  \n",
    "Each line is separated by newline '<code>\\n</code>'  \n",
    "Each word within line is separated by comma '<code>,</code>'  \n",
    "  \n",
    "Output is saved to <code>cleaned.txt</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "VALID_CHAR_REGEX = \"[a-zA-Z0-9]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open input text\n",
    "# https://www.ic.unicamp.br/~stolfi/voynich/mirror/reeds/docs/FSG.txt\n",
    "text = open('FSG.txt', 'r').read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove lines with no text\n",
    "parsed = []\n",
    "\n",
    "for line in text:\n",
    "    if line == \"\":\n",
    "        continue\n",
    "    if line == \"\\x0c\":\n",
    "        continue\n",
    "    if line.startswith(\"#\"):\n",
    "        continue\n",
    "    if not re.search(VALID_CHAR_REGEX, line):\n",
    "        continue\n",
    "\n",
    "    parsed.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dashes and equality signs from end of each line\n",
    "cleaned = []\n",
    "\n",
    "for line in parsed:\n",
    "    # last valid char position\n",
    "    endpos = 0\n",
    "    for i, char in enumerate(line):\n",
    "        if re.match(VALID_CHAR_REGEX, char):\n",
    "            endpos = i\n",
    "\n",
    "    cleaned.append(line[:i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "file = open(\"cleaned.txt\", \"w\")\n",
    "for line in cleaned[:-1]:\n",
    "    file.write(line + \"\\n\")\n",
    "file.write(cleaned[-1])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting valid words\n",
    "This step further facilitates the analysis of the text.\n",
    "\n",
    "Separate words are now extracted to a single list of words.  \n",
    "Some words have not been transcripted fully and some characters may not be identified.  \n",
    "Since it is not definite what the words may actually be, they are going to be ommited. \n",
    "  \n",
    "Output is saved to <code>words.txt</code>, one word per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open input file\n",
    "text = open('cleaned.txt', 'r').read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract valid words from each line\n",
    "words = []\n",
    "\n",
    "\n",
    "\n",
    "for line in text:\n",
    "    list = line.split(\",\")\n",
    "    for word in list:\n",
    "        if re.match(\"^\"+VALID_CHAR_REGEX+\"*$\", word):\n",
    "            words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "file = open(\"words.txt\", \"w\")\n",
    "for line in words[:-1]:\n",
    "    file.write(line + \"\\n\")\n",
    "file.write(words[-1])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing words\n",
    "\n",
    "Valid words are being mapped their count of occurance within the text.  \n",
    "\n",
    "Based on this data, the Zipf Law is applied to check if the text is written in a realistic human language.  \n",
    "Further analysis includes graphing and visualising the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open input file\n",
    "text = open('words.txt', 'r').read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map occurance count for each word\n",
    "wojnicz_dict = {}\n",
    "\n",
    "for word in text:\n",
    "    if word in wojnicz_dict.keys():\n",
    "        wojnicz_dict[word] += 1\n",
    "    else:\n",
    "        wojnicz_dict[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort words by occurance descending\n",
    "wojnicz_dict_desc = dict(sorted(wojnicz_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "wojnicz_dict_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get occurance percentages\n",
    "word_count = len(text)\n",
    "occurance_percentage = {}\n",
    "\n",
    "for word in wojnicz_dict_desc.keys():\n",
    "    occurance_percentage[word] = wojnicz_dict_desc[word] / word_count\n",
    "\n",
    "occurance_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate zipf value for each word (occurance percentage * index) \n",
    "zipf_values = {}\n",
    "\n",
    "for i, word in enumerate(occurance_percentage.keys()):\n",
    "    zipf_values[word] = occurance_percentage[word] * (i+1) * 100\n",
    "\n",
    "zipf_values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- sprawdzić czy to wgl to o co chodzi bo robiłem z pamięci\n",
    "- jakieś wykresy gośc chciał\n",
    "- potem to samo z innym językiem z wiki\n",
    "  - sformatować do pliku z pojedynczymi słowami\n",
    "  - zamienić powyższe komórki na funkcje żeby nie pisać tego samego dwa razy\n",
    "  - przeanalizować podobnie i porównać\n",
    "- potem jeszce jakiś graf dwudzielny (????????????)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5cb8aafaeb8e0a18ee17c25f5e27cfa4722b633ed7a736629248d19340d2b0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
